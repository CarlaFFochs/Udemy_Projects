{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Choose the right estimator/algoritm for our problems.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2pctglIMArof",
        "SY_RC_FYH1MU",
        "1yQ2XhYNU7p1",
        "uWCxlS5jWw_h",
        "y5MonZM_bxbb",
        "6Zkhj_tobhDA",
        "eODX2G62FEvy",
        "mdMvuKRUFnjk",
        "6-06zv2fHfnc",
        "1NTCovBAHvTb",
        "z-0XzhCcHr-D",
        "oI5R8xgEbz0Y",
        "oPzXA5r0gACy",
        "JBjdTxBIidz5"
      ],
      "authorship_tag": "ABX9TyMtGdv+oLTQ+8VBLasPf2fQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlaFFochs/Udemy_Projects/blob/main/2_Choose_the_right_estimator_algoritm_for_our_problems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iwC3JUNC29y"
      },
      "source": [
        "#2.Choosing the right estimator/algoritm for your problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmCVp_9xOwcW"
      },
      "source": [
        "Some things to note:\n",
        "\n",
        "* Sklearn refers to ML models, algorithms as estimators.\n",
        "* Classification problem - predicting a category (heart disase or not)\n",
        "  * Sometimes you'll see 'clf' (short for classifier') used as a classification estimator\n",
        "* Regression problem - predicting a number (selling price of a car) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0M63U_0PUHe"
      },
      "source": [
        "#Consultar (alla podem saber quin model escollor): Sklearn machine learning model map --> "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obU9m9c3RBFF"
      },
      "source": [
        "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34pmboHmPlT1"
      },
      "source": [
        "Toys/ Real worda data sets for practicing  --> https://scikit-learn.org/stable/datasets/toy_dataset.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK6uP_K8OsvC"
      },
      "source": [
        "## 2.1 Picking a ML Model for a regression problem "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EOrc9mAPJkg"
      },
      "source": [
        "Let's use California data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwKJiLhaSKGn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxy6eA5rPMiP"
      },
      "source": [
        "#Get California Housing fata set\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcQMKHOzPcf4"
      },
      "source": [
        "#We can see that it's a dictionary\n",
        "#We want to use the FEATURES to predict the TARGET\n",
        "\n",
        "#Create a DataFrame with the data & feature_names\n",
        "\n",
        "housing_df = pd.DataFrame(housing[\"data\"], columns = housing[\"feature_names\"])\n",
        "housing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo23PlbZSoEI"
      },
      "source": [
        "housing_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyzlWax3QDeu"
      },
      "source": [
        "#We have to create a column within the DataFrame \"housing_df\" with the data that is in \"housing\", within \"target\"\n",
        "\n",
        "housing_df[\"MedHouseVal\"] = housing[\"target\"]\n",
        "housing_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApsiEpMqQE7Z"
      },
      "source": [
        "housing_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIkNIMmhTZew"
      },
      "source": [
        "housing_df[\"target\"] = housing[\"target\"]\n",
        "housing_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mowryIiJT4OR"
      },
      "source": [
        "housing_df.drop(\"MedHouseVal\", axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdU0v7viT-Ww"
      },
      "source": [
        "#Split out data into FEATURES and TARGET\n",
        "\n",
        " #Import algorithm/estimator --> We search scikit learn ML model map\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        " #Setup random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create the data\n",
        "X = housing_df.drop(\"target\", axis = 1)\n",
        "y = housing_df[\"target\"]   #median house price in ~100,000$\n",
        "\n",
        "#Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "#Instantiate and fit the model (on the training set)\n",
        "model = Ridge()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Check the score of the model (on the test set)\n",
        "model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZq1vZGFUeP4"
      },
      "source": [
        "#Return the Coefficient of Determination --> We can google it\n",
        "#How strong is the relationship between two variables\n",
        "#For this reason the 0,99 is taking the relationship between the features and target\n",
        "\n",
        "#Higher value is 1 (h--> how predictive the features (X) of the target value (y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGA2IOX08spl"
      },
      "source": [
        "We can try another METHOD  --> https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjF91lAM8slb"
      },
      "source": [
        "We will try a different Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOiosxMY8_6z"
      },
      "source": [
        "#althought our result was really goof"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6SR7i2E9E1S"
      },
      "source": [
        "What if \"Ridge\" didn't work ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqwynHHZ9M9J"
      },
      "source": [
        "Ensemble methods is to **combine the predicitons** of several base estimators built with a given learning algorithm in order to improve generalizability / robustness of a model --> https://scikit-learn.org/stable/modules/ensemble.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "467LyPxP9kmW"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi1JGBnN_r0_"
      },
      "source": [
        "#Import the RandomForestRegressor model class from the ensemble module\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "#Setup random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create the data \n",
        "X = housing_df.drop(\"target\", axis = 1)\n",
        "y = housing_df[\"target\"]\n",
        "\n",
        "#Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size = 0.2)\n",
        "\n",
        "#Create random Forest model\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Check the score of the model (on the test set)\n",
        "model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pctglIMArof"
      },
      "source": [
        "##2.1 Picking a ML Model for a classifiaction model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpdUVA90JZU7"
      },
      "source": [
        "#Choose a model to practice --> Toy data sets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY_RC_FYH1MU"
      },
      "source": [
        "##2.2 Choosing an estimator for classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzFwVyf_H1Z5"
      },
      "source": [
        "Let's goo to the map....https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjuN-E5oH1gM"
      },
      "source": [
        "heart_disease = pd.read_csv(\"/content/drive/MyDrive/MASTER DATA SCIENCE/M0/M0 - UDEMY/data/heart-disease.csv\")\n",
        "heart_disease.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCE8TCUMMlPv"
      },
      "source": [
        "heart_disease.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJPoJWHvH1yd"
      },
      "source": [
        "len(heart_disease) #we check the lenght of the data in order to pick the model\n",
        "#We've arrived to the \"Linear SVC\" (answering the questions of the map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_010kD7H13x"
      },
      "source": [
        "#Import the LinearSVC estimator class\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Set up random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "#Make the data\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "#Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size = 0.2)\n",
        "\n",
        "\n",
        "#Instantiate LInearSVC\n",
        "clf = LinearSVC(max_iter=10000) #we include max_iter as it appears a warining\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Evaluate LinearSVC()\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCSQ2R4H190"
      },
      "source": [
        "heart_disease[\"target\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aH4gSJKH2Cc"
      },
      "source": [
        "#if we were guessing if it would have heart_disesase or not, we will have a 86,68% of accuracy \n",
        "#there are only 2 clases\n",
        "#in the example of Udemy, it gives a score of 50%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUPVRuLaH2G9"
      },
      "source": [
        "#Import the RandomForestClassifier estimator class\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Set up random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "#Make the data\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "#Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size = 0.2)\n",
        "\n",
        "\n",
        "#Instantiate RandomForestClassifier\n",
        "clf = RandomForestClassifier() \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Evaluate RandomForestClassifier\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeNmBXiRH2Lr"
      },
      "source": [
        "#it performs worst than before"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2_23mgnH2QO"
      },
      "source": [
        "**Tidbit**:\n",
        "  1. If you have **structured data,** use **ENSEMBLE METHODS**\n",
        "  2. If you have **unstructured data**, use **DEEP LEARINING** or **TRANSFER LEARNING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3YS3SsHQ5Dv"
      },
      "source": [
        "heart_disease"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfP_SQQFUfKT"
      },
      "source": [
        "# 3.Fit the model/algorithm on our data and use it to make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yQ2XhYNU7p1"
      },
      "source": [
        "##3.1 Fitting the model to the data\n",
        "\n",
        "Diferent names for:\n",
        "* \"X\" = features, features variables, data\n",
        "* \"y\" = labels, targets, target variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TKR9Kb-Unq2"
      },
      "source": [
        "#Import the RandomForestClassifier estimator class\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Set up random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "#Make the data\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "#Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size = 0.2)\n",
        "\n",
        "\n",
        "#Instantiate RandomForestClassifier\n",
        "clf = RandomForestClassifier() \n",
        "\n",
        "#Fit the model to the data (traning ML model, the model is going to find paterns)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Evaluate RandomForestClassifier (use the patters the model has learn)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VPQKws0VNn2"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VstMhGm4VO4e"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvDxU-VwVR7Z"
      },
      "source": [
        "y.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWCxlS5jWw_h"
      },
      "source": [
        "##3.2 Make predicitions using a ML model\n",
        "\n",
        "2 ways of make predictions:\n",
        "  1. predict() --> will give you a **SINGLE LABEL**  for each sample\n",
        "  2. predict_proba() --> returns the **PROBABILITIES** of a classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5MonZM_bxbb"
      },
      "source": [
        "###Make predicitons with **predict()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p8Hme75YYme"
      },
      "source": [
        "#Use a trained model to make predictions\n",
        "#the model has learn for the features, so the predict has to be pass the same format of data it has learned3#\n",
        "\n",
        "#clf.predict(np.array([1,7,7,8,9]))\"\" #this is an error...\n",
        "\n",
        "    #ValueError: Expected 2D array, got 1D array instead:\n",
        "    #array=[1. 7. 7. 8. 9.].\n",
        "    #Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1qfeP5UZWC-"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2apOCe7ZvzI"
      },
      "source": [
        "clf.predict(X_test) #our model has trained on our train data and it has never seen the test data\n",
        "\n",
        "#to predict if we have heart disease or not, the result is the target (y predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYs5iE3hZ1Wc"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMmOfzQMZ951"
      },
      "source": [
        "np.array((y_test)) #this is the truth label, and the matrix above is the predicitons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMkXmwVWaAQp"
      },
      "source": [
        "#Compare predictions to truth labels to evaluate the model\n",
        "\n",
        "y_preds = clf.predict(X_test) #making productions with my model and save them\n",
        "np.mean(y_preds == y_test) #comparing the predictions to the \"ground truth labels\" (Y) with the original data set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_5TZnD3bSNQ"
      },
      "source": [
        "#we are comparing how well predicted, compare the arrays 1 by 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vpSUOXgatqO"
      },
      "source": [
        " clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSJ-tbXebQVH"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_test) #\"y_test\" == real data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zkhj_tobhDA"
      },
      "source": [
        "### Make predicitons with **predict_proba()**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PKCbn17cGn6"
      },
      "source": [
        "https://scikit-learn.org/0.15/modules/generated/sklearn.svm.libsvm.predict_proba.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1lDY54McOCY"
      },
      "source": [
        "# predict_proba() returns probabilities of a classification label\n",
        "clf.predict_proba(X_test[:5])\n",
        "\n",
        "#aqui veiem la probabilitat de que tinguis el valor \"0\" o \"1\" (heart disease or not)\n",
        "#si tinguessim més X class, tindriem X columnes, per això el array es de 2 columnes "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HetNkFHHcRUk"
      },
      "source": [
        "#Let's predict()) on the same data...\n",
        "clf.predict(X_test[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTT72KGZchfP"
      },
      "source": [
        "#ara comparem la array 1 amb la array 2\n",
        "#veiem que hi ha una relació\n",
        "\n",
        "#per el primer valor de la array2 --> 0 // tenim que el de l'esquerra és més gran i el de la dreta més petit\n",
        "#però per el segon valor de la array2 --> 1 // el valor de l'esquerra és més petit que el de la dreta\n",
        "#VEIEM QUE VA SEGUINT LA MATEIXA RELACIÓ si comparem array1 amb array2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35XIuJnletx0"
      },
      "source": [
        "#per la primera mostra tenim una predicció de \"0\", per tant, tenim el 89% de probilitat d'acertar i 11% d'equivocar-nos\n",
        "#per la segona mostra tenim una predicció de \"1\", per tant, tenim el 51% de probabilitat d'acertar i 49% d'equivocar-nos\n",
        "#per la tercera mostra tenim una predicció de \"1\", per tant, tenim el 57% de probilitat d'acertar i 43% d'equivocar-nos\n",
        "#per la quarta mostra tenim una predicció de \"0\", per tant, tenim el 84% de probabilitat d'acertari 16% d'equivocar-nos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwDiSz3zdT7R"
      },
      "source": [
        "X_test[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO6CQCqodbTj"
      },
      "source": [
        "heart_disease[\"target\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_6D-WTJdjdC"
      },
      "source": [
        "predict() can also be used for regression models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMtep5ic8jLx"
      },
      "source": [
        "housing_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM7sXavU9NBS"
      },
      "source": [
        "**NOTA:** \"Instantiation\" is the creation of a real instance or particular realization of an abstraction or template such as a class of objects or a computer process. ... The object is an executable file that you can run in a computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vQsVNan8kqS"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor #trying to predict a number\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create the data\n",
        "X = housing_df.drop(\"target\", axis = 1)\n",
        "y = housing_df[\"target\"]\n",
        "\n",
        "#Split the data into traning and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2)\n",
        "\n",
        "#Create model instance\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "#Fit the model to the data\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "#Make predictions\n",
        "y_preds = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKgedJxm9mqT"
      },
      "source": [
        "y_preds[:10] #are mot in the same format as \"target\", which is the one we are comparing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLPRMu61-C1j"
      },
      "source": [
        "np.array(y_test[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdqHsmDN-M8i"
      },
      "source": [
        "len(y_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLZRtfxl-P1C"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmKH6kfx-RYz"
      },
      "source": [
        "#Comprare the predicitons to the truth\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mean_absolute_error(y_test, y_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R8168XP-pES"
      },
      "source": [
        "#this reasult is the diference of y_preds and y_test and the average between all these diference (all the array) --> scikit learn does it automatically with \"mean_absolute_error\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a34nmmxF_GL5"
      },
      "source": [
        "housing_df[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJenSDg5_UxC"
      },
      "source": [
        "#4.Evaluating a ML model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eODX2G62FEvy"
      },
      "source": [
        "###Three ways to evaluate Scikit-Learn models/estimators:\n",
        "\n",
        "1. Estimator's built-in \"score()\" method\n",
        "2. The \"scoring\" parameter\n",
        "3. Problem-specific metric functions\n",
        "\n",
        "You can reed more about these here: https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdMvuKRUFnjk"
      },
      "source": [
        "##4.1 Evaluating a model with the 'score' method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8GeV1QaF4ab"
      },
      "source": [
        "heart_disease"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeZxwjMqFt9k"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create X & y\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "#Split de data into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2)\n",
        "\n",
        "#Create the model instance\n",
        "clf = RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "#Fit the model with the training data\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6cO3bo5GhB8"
      },
      "source": [
        "#The highest value for the .score() methods is 1.0, the lowest 0.0\n",
        "clf.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTjl2w_SGpqV"
      },
      "source": [
        "#100% of accuraccy.\n",
        "#Why the model is getting a perfect score? --> The model can predict perfectly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56c6MUOSG_e8"
      },
      "source": [
        "clf.score(X_test, y_test) #learn patterns to make predicitons in data that we've haven't seen. Before the model has already seen it. If we get 100% in test, we must check the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-06zv2fHfnc"
      },
      "source": [
        "####Let's try with n_estimators = 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "213TzAgyHHcE"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create X & y\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "#Split de data into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2)\n",
        "\n",
        "#Create the model instance\n",
        "clf = RandomForestClassifier(n_estimators = 5)\n",
        "\n",
        "#Fit the model with the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Evaluate the model\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itxzIT8tHUoD"
      },
      "source": [
        "#we get a less score... "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NTCovBAHvTb"
      },
      "source": [
        "####Let's try with n_estimators = 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyrKygPGHrPM"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create X & y\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "#Split de data into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2)\n",
        "\n",
        "#Create the model instance\n",
        "clf = RandomForestClassifier(n_estimators = 2)\n",
        "\n",
        "#Fit the model with the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Evaluate the model\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-0XzhCcHr-D"
      },
      "source": [
        "###Let's use the score() on our regression problem..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_XGlqnxIAwD"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor #we are prediciting a number\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create X & y\n",
        "X = housing_df.drop(\"target\", axis = 1)\n",
        "y = housing_df[\"target\"]\n",
        "\n",
        "#Split de data into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2)\n",
        "\n",
        "#Create the model instance\n",
        "model = RandomForestRegressor(n_estimators = 50) #the higher n_estimators is, higher time it will take the model to fit (actually we are only fitting 100)\n",
        "#Fit the model with the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Evaluate the model\n",
        "model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhXHDcrFIK5m"
      },
      "source": [
        "model.score(X_test,y_test) #this result was with n_estimators = 2 \n",
        "#the result is the coeficient of determination R^2  is the propotion of the variation in the dependet variable that is predicatble from the independent variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu8ZHQCLP4B_"
      },
      "source": [
        "Es importante saber que el resultado del coeficiente de determinación oscila entre 0 y 1. Cuanto más cerca de 1 se sitúe su valor, mayor será el ajuste del modelo a la variable que estamos intentando explicar. De forma inversa, cuanto más cerca de cero, menos ajustado estará el modelo y, por tanto, menos fiable será."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMq8w-DNKCE0"
      },
      "source": [
        "#\"target\" variable is the dependent on the \"features\" varianles (are the independent variables, independently combine to form Y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kfFxwk4KZQt"
      },
      "source": [
        "housing_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny-8LC_yKuHE"
      },
      "source": [
        "y_test.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-MOxcyxRn6m"
      },
      "source": [
        "##4.2 Evaluating a model using the \"scoring\" parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P9iYLKnlZNX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoSj0iVqZC_3"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score #we are prediciting a number\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#Create X & y\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "#Split de data into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2)\n",
        "\n",
        "#Create the model instance\n",
        "clf = RandomForestClassifier(n_estimators = 100) \n",
        "#Fit the model with the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Evaluate the model\n",
        "clf.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZOV4PB5ZX9g"
      },
      "source": [
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okN5B0JZZvr3"
      },
      "source": [
        "cross_val_score(clf, X, y) #returns an array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVO-Nb4sab8q"
      },
      "source": [
        "**5-fold Cross-validation:** 5 different splits (is the default). Model is trained on 5 different versions of training fata and evaliated on 5 differernt versions of the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx5oFeHoaDhH"
      },
      "source": [
        "cross_val_score(clf, X, y, cv = 5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o8nSK7XaRSH"
      },
      "source": [
        "cross_val_score(clf, X, y, cv = 10) #the first split is the best one in this case"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvsEblCfbNCI"
      },
      "source": [
        "#take the average of the k-fold\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#Single training and test split score\n",
        "clf_single_score = clf.score(X_test, y_test)\n",
        "\n",
        "#Take the mean of 5-fold cross-validation score\n",
        "clf_cross_val_score = np.mean(cross_val_score(clf, X, y , cv = 5))\n",
        "\n",
        "#Compare the two\n",
        "clf_single_score, clf_cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI5R8xgEbz0Y"
      },
      "source": [
        "####Cross validation is slighly lower 82% however --> is better the cross validation metric than the non-cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lACr3fDeLZ5"
      },
      "source": [
        "#Default scoring parameter of classifier = mean accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ORIkQ8DcGG4"
      },
      "source": [
        "# Scoring parameter set to None by default\n",
        "cross_val_score(clf, X, y, cv = 5 , scoring = None) #we can change the \"scoring\" parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZbYcLOcepYQ"
      },
      "source": [
        "![title](https://i1.wp.com/www.business-science.io/assets/2020-01-21-tune/nested_hyperparameter_tuning_process.jpg?w=578&ssl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPzXA5r0gACy"
      },
      "source": [
        "###4.2.1 Classification model metrics\n",
        "\n",
        "1. Accuracy\n",
        "2. Area under ROC curve\n",
        "3. Confusion matrix\n",
        "4. Classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-OcQ9o9tgjc"
      },
      "source": [
        "###**1. Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2fagUe4igI0"
      },
      "source": [
        "heart_disease.head()\n",
        "\n",
        "#how likely is going to predict likely is it to predict the RIGHT target?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QzEUghRgPrh"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators= 100)\n",
        "cross_val_score = cross_val_score(clf, X, y , cv = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxE7yalQh3MR"
      },
      "source": [
        "np.mean(cross_val_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wngt8GNuh934"
      },
      "source": [
        "print(f\"Heart Disease Classifier Cross-Validated Accuracy: {np.mean(cross_val_score)*100:.2f}%\") #the model will predict 82.48& de right label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBjdTxBIidz5"
      },
      "source": [
        "### **2. Area under the receiver operating characteristic curve (AUC/ROC)***\n",
        "\n",
        "* Area under curve (AUC)\n",
        "* ROC curve --> are a comparison of a model true positive rate (tpr) versus a models false positive rate (fpr)\n",
        "\n",
        "    * **True Positive** = model predicts 1 when the truth is 1 (good prediction)\n",
        "    * **False Positive**= model predicts 1 when the truth is 0 (bad predicition)\n",
        "    * **True Negative** = model predicts 0 when the truth is 0 (right prediciton)\n",
        "    * **False Negative** = model predict 1 when the truth is 0 (bad prediction)\n",
        "\n",
        "0 = NEGATIVE class (NO heart disease)\n",
        "\n",
        "1 = POSITIVE class (heart disease)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5GhdtV2jctZ"
      },
      "source": [
        "#Create X_test... etc\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJFO5E_5l54x"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "#fit the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Make predicitons with probabilities\n",
        "y_probs = clf.predict_proba(X_test)\n",
        "y_probs[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7lD6SKQmJ56"
      },
      "source": [
        "#[ 0 , 1] \n",
        "#the first value 58% is the probability to be 0 // and 42% is the probability to be 1\n",
        "\n",
        "y_probs_positive = y_probs[:, 1] #only getting the column 1\n",
        "y_probs_positive[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPPYcNBtm-dq"
      },
      "source": [
        "#Calculate fpr, tpr and thresholds (umbrales)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)\n",
        "\n",
        "#check the false positive rates\n",
        "fpr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KczqBNanNna"
      },
      "source": [
        "#Create a function for plotting ROC curves\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_roc_curve(fpr, tpr):\n",
        "  \"\"\"\n",
        "  Plots a ROC curve given the false positive rate (fpr) and true positive rate (tpr) of a model.\n",
        "  \"\"\"\n",
        "  # Plot a roc curve\n",
        "  plt.plot(fpr,tpr, color = \"orange\", label = \"ROC\")\n",
        "  # Plot line with no predictive power (baseline)\n",
        "  plt.plot([0,1], [0,1], color = \"darkblue\", linestyle = \"--\", label= \"Guessing\")\n",
        "\n",
        "  # Customize the plot\n",
        "  plt.xlabel(\"False positive rate (fpr)\")\n",
        "  plt.ylabel(\"True positive rate (tpr)\")\n",
        "  plt.title (\"Receiver Operating Characteristic (ROC) Curve\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_roc_curve(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3wnO10eppqr"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score #auc (area under cruve)\n",
        "\n",
        "roc_auc_score(y_test, y_probs_positive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQcsCiCqIUK"
      },
      "source": [
        "# Plot perfect ROC curve and AUC score\n",
        "fpr, tpr, threshoulds = roc_curve(y_test, y_test)\n",
        "plot_roc_curve(fpr,tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToA4QfnMqtab"
      },
      "source": [
        "# Perfect AUC score, if it's 1 is that every thing is TP or FP\n",
        "roc_auc_score(y_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw09VwFmqzAr"
      },
      "source": [
        "**Reading Extension:** ROC Curve + AUC\n",
        "\n",
        "When you first encounter them, ROC Curve and AUC (area under curve) metrics can be a little confusing. But not to worry, with a little practice, they'll start to make sense.\n",
        "\n",
        "In a nutshell, what you should remember is:\n",
        "\n",
        "* ROC curves and AUC metrics are evaluation metrics for binary classification models (a model which predicts one thing or another, such as heart disease or not).\n",
        "\n",
        "* The ROC curve compares the true positive rate (tpr) versus the false positive rate (fpr) at different classification thresholds.\n",
        "\n",
        "* The AUC metric tells you how well your model is at choosing between classes (for example, how well it is at deciding whether someone has heart disease or not). A perfect model will get an AUC score of 1.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJqIFXPrtX1F"
      },
      "source": [
        "### **3.Confusion Matrix**\n",
        "\n",
        "The next way to evaluate a classification model is by using a confusion matrix\n",
        "\n",
        "A confusion matrix is a quick way to **compare the labels a model predicts** and the **actual labels it was supposed to predict**.\n",
        "\n",
        "In essence, this gives you an idea of where the model is getting confused.\n",
        "\n",
        "See here --> https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9LLkYVRxu5U"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_preds = clf.predict(X_test)\n",
        "\n",
        "confusion_matrix(y_test, y_preds) #y_test == y_true\n",
        "\n",
        "#were the model is getting confused is on the diagonal of \"6\" \n",
        "#the correct is the diagonal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW-S2Ohvyr31"
      },
      "source": [
        "# Visualize confusion matrix with pd.crosstab()\n",
        "pd.crosstab(y_test, \n",
        "            y_preds,\n",
        "            rownames = [\"Actual Labels\"],\n",
        "            colnames = [\"Predicted Labels\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoJE2pgcT18a"
      },
      "source": [
        "![title](https://i1.wp.com/dataaspirant.com/wp-content/uploads/2020/08/3_confusion_matrix.png?ssl=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXdWX4z-y8k8"
      },
      "source": [
        "24 + 5 + 8 + 24\n",
        "\n",
        "#8 False negatives\n",
        "#5 False Positives"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GVnQBQfzVc0"
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ATT5DQgVXE5"
      },
      "source": [
        "# How to install a conda package into the current enviroment from a Jupitor Notebook\n",
        "import sys\n",
        "!conda install --yes --prefix {sys.prefix} seaborn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWcWwDdrzYyc"
      },
      "source": [
        "# Make our confusion matrix more visual with Seabrn's heatmap()\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the font scale\n",
        "sns.set(font_scale = 1.5)\n",
        "\n",
        "# Create a confusion matriz\n",
        "conf_mat = confusion_matrix(y_test, y_preds)\n",
        "\n",
        "# Plot it using Seaborn\n",
        "sns.heatmap(conf_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl893EkfU_v0"
      },
      "source": [
        "# We want numbers in the confusion matrix "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY7tbIZtUfEY"
      },
      "source": [
        "#### Creating a confusion matrix using Scikit-Learn\n",
        "\n",
        "To use the new methods of creating a confusion matrix with Scikit-Learn you will need scklearn version 1.0+"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFK7zXndZuWT"
      },
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIXoto6ndzJe"
      },
      "source": [
        "###There are two options:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqcIepVHkV85"
      },
      "source": [
        "###OPTION 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l6SWqz2Zxmp"
      },
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(estimator = clf, X=X, y=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvSeohJNdcp0"
      },
      "source": [
        "# We have more values because we are passing the whole data X and y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLVUSARcd5oH"
      },
      "source": [
        "###OPTION 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLu4p1I2d9g_"
      },
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_true=y_test, y_pred=y_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exQuamEBeGoo"
      },
      "source": [
        "### 4.Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_jyU5ASfl5e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_preds))\n",
        "\n",
        "#our model is balanced (support is 29/32 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "192tUZFQfsYE"
      },
      "source": [
        "* **Precision** - Indicates the proportion of positive identifications (model predicted class 1) which werea actually correct. A model which produces no false positives has a precision of 1.0\n",
        "\n",
        "* **Recall** - Indicates the proportion of actual postives which were correctly classified. A model which produces no false negatives has a recall of 1.0\n",
        "\n",
        "* **F1 Score** - A combination of precision and recall. A perfect model achieves an F1 score of 1.0\n",
        "\n",
        "* **Support** - The number of samples each metric was calculated on\n",
        "\n",
        "* **Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0\n",
        "\n",
        "* **Mactro avg** - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn't class imbalance into account, so of you do have class imbalances, pay attention to this metric.\n",
        "\n",
        "* **Weighted avg** - Short for weigheted average, the weightened average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. will give a high value when one class out performs another due to having more samples)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecEOfHmyihOu"
      },
      "source": [
        "# Where precision and recall become valuable\n",
        "\n",
        "# Here we have massive clase UNBALANCED --> only one example where the label will be 1\n",
        "\n",
        "disease_true = np.zeros(10000)\n",
        "disease_true[0] = 1 #only one positive case\n",
        "\n",
        "disease_preds = np.zeros(10000) #model predicts every case as 0 (it misses the 1 prediction)\n",
        "\n",
        "pd.DataFrame(classification_report(disease_true,\n",
        "                                   disease_preds,\n",
        "                                   output_dict=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kwPrp2ZjE8Z"
      },
      "source": [
        "#accuracy is 0.999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izkoPcRxjuo3"
      },
      "source": [
        "Check --> Model evalutation classification scikit-learn --> https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JoAGSJElb8i"
      },
      "source": [
        "##4.2.2  Regression model evalutation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_pHCaLwn2Nf"
      },
      "source": [
        "Model evalutation metrics documentantion --> https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n",
        "\n",
        "The ones we're going to cover are🇰\n",
        "\n",
        "1. R^2 or coefficient of determination\n",
        "2. Mean Absolut error (MAE)\n",
        "3. Mean Squared Error (MSE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hNkhchqp3Ql"
      },
      "source": [
        "### 4.2.2.1.Evalutating a Regression Model 1 (R2 Score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Riq7pOITq14u"
      },
      "source": [
        "**R^2:** Compares your predicitons to the mean of the targets. Values can range for negative infinity (a very poor model) to 1. For example, example if all your model does it predict the  mean of the targets, it's R^2 value will be 0. And if your model perfectly preficts a range of numbers it's R^2 value would be 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GLWv9C0o3B8"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "X = housing_df.drop(\"target\", axis = 1)\n",
        "y= housing_df[\"target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2)\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "model.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XqTOd6jo2_z"
      },
      "source": [
        "model.score(X_test, y_test) #the value we get is R^2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LMMrNAmo29Q"
      },
      "source": [
        "housing_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCt7_KKAo26I"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fQWl9EEo22_"
      },
      "source": [
        "y_test.mean() #our model just predicted 2.05 for all this values, we will get a score of 0.99"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IawJAN3Jo20p"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Fill an array with y_test mean\n",
        "y_test_mean = np.full(len(y_test), y_test.mean()) #fill each sample wiht the y_test.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd8vwdSCo2xE"
      },
      "source": [
        "y_test_mean[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BUUk6Vqo2uI"
      },
      "source": [
        "r2_score(y_true= y_test,\n",
        "         y_pred = y_test_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIM7jO7fr4Xf"
      },
      "source": [
        "#We are evalutating to see how well is doing at predicting the target value from the features\n",
        "r2_score(y_true= y_test,\n",
        "         y_pred = y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On1V0doBlkyF"
      },
      "source": [
        "### 4.2.2.3 Evalutating a Regression Model 2 (MAE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlOi2AGUsHLg"
      },
      "source": [
        "**Mean Absolut Error (MAE)** : is the average of the absolut differences between predicitons and actual values.\n",
        "It gives you an idea of how wrong your models predicitons are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7IMdT09spaO"
      },
      "source": [
        "#MAE\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "y_preds = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_preds)\n",
        "mae #on average each on of our predictions (y_pred) is +- 0.000190 the y_test value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLH8vu_xt70A"
      },
      "source": [
        "y_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSwygaV0spSf"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ2RsgiespKn"
      },
      "source": [
        "df = pd.DataFrame(data = {\"Actual values\": y_test, \"Predicted values\": y_preds})\n",
        "df[\"Differences\"] = df[\"Predicted values\"] - df[\"Actual values\"]\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1N3vxx2vCmE"
      },
      "source": [
        "df[\"Differences\"].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0xcr7iovL2k"
      },
      "source": [
        "#MAE using abs and differences \n",
        "np.abs(df[\"Differences\"].mean()) #aqui ens hauria de donar el mateix valor que a dalt MAE (crec que no em dona bé...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayAP5LRXlo2r"
      },
      "source": [
        "### 4.2.2.4 Evaluating a Regression Model 3 (MSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC3VugLBsH2a"
      },
      "source": [
        "**Mean Squared Error (MSE)** : is the mean of the square of the errors between actual and predictes values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf072HinwhL_"
      },
      "source": [
        "# MSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_preds = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_preds)\n",
        "mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwyIjCXAwhn1"
      },
      "source": [
        "df[\"Squared differences\"] = np.square(df[\"Differences\"])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR41Jcr5whxo"
      },
      "source": [
        "# Calculate MSE by hand\n",
        "squared = np.square(df[\"Differences\"])\n",
        "squared.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b9_tVdowh40"
      },
      "source": [
        "df_large_error = df.copy()\n",
        "df_large_error.iloc[0][\"Squared differences\"] = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_6RoaOvwiBW"
      },
      "source": [
        "df_large_error.head() #no se'm actualitza el valor de la \"Squared differences\" a la taula, no em surt el 16, sino el 1.906..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl0eskVSwiQ1"
      },
      "source": [
        "# Calculate MSE with large error\n",
        "df_large_error[\"Squared differences\"].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QEIrGOwyZcf"
      },
      "source": [
        "df_large_error.iloc[1:100] = 20\n",
        "df_large_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YaAxS7u3kNG"
      },
      "source": [
        "#SUMMARY OF ML MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHNZE6-r1MpB"
      },
      "source": [
        "\n",
        "\n",
        "1) CLASSIFICATION MODEL EVALUTATION metrics/techniques \n",
        "* **Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0.\n",
        "\n",
        "* **Precision** - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
        "\n",
        "* **Recall** - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
        "\n",
        "* **F1 score** - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
        "\n",
        "* **Confusion matrix** - Compares the predicted values with the true values in a tabular way, if 100% correct, all values in the matrix will be top left to bottom right (diagonal line).\n",
        "\n",
        "* **Cross-validation** - Splits your dataset into multiple parts and train and tests your model on each part then evaluates performance as an average.\n",
        "\n",
        "* **Classification report **- Sklearn has a built-in function called classification_report() which returns some of the main classification metrics such as precision, recall and f1-score.\n",
        "\n",
        "* **OC Curve** - Also known as receiver operating characteristic is a plot of true positive rate versus false-positive rate.\n",
        "\n",
        "* **Area Under Curve (AUC) Scor**e - The area underneath the ROC curve. A perfect model achieves an AUC score of 1.0.\n",
        "\n",
        "***Which classification metric should you use?***\n",
        "\n",
        "* **Accuracy **is a good measure to start with if all classes are balanced (e.g. same amount of samples which are labelled with 0 or 1).\n",
        "\n",
        "* **Precision** and recall become more important when classes are imbalanced.\n",
        "\n",
        "* **If false-positive predictions** are worse than false-negatives, aim for higher precision.\n",
        "\n",
        "* If **false-negative** predictions are worse than false-positives, aim for higher recall.\n",
        "\n",
        "* **F1-score** is a combination of precision and recall.\n",
        "\n",
        "* A **confusion matrix** is always a good way to visualize how a classification model is going.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ppQNfNg0zYy"
      },
      "source": [
        "2) REGRESSION MODEL EVALUTATION metrics/techniques\n",
        "\n",
        "* **R^2 (pronounced r-squared)** or the coefficient of determination - Compares your model's predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1.\n",
        "\n",
        "* **Mean absolute error (MAE)** - The average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your predictions were.\n",
        "\n",
        "* **Mean squared error (MSE)** - The average squared differences between predictions and actual values. Squaring the errors removes negative errors. It also amplifies outliers (samples which have larger errors).\n",
        "\n",
        "***Which regression metric should you use?***\n",
        "\n",
        "* **R2** is similar to **accuracy**. It gives you a quick indication of how well your model might be doing. Generally, the closer your R2 value is to 1.0, the better the model. But it doesn't really tell exactly how wrong your model is in terms of how far off each prediction is.\n",
        "\n",
        "* **MAE** gives a better indication of how far off each of your model's predictions are on average.\n",
        "\n",
        "* As for **MAE** or **MSE**, because of the way **MSE** is calculated, squaring the differences between predicted values and actual values, it amplifies larger differences. Let's say we're predicting the value of houses (which we are).\n",
        "\n",
        "  * **Pay more attention to MAE**: When being $10,000 off is twice as bad as being $5,000 off.\n",
        "\n",
        "  * **Pay more attention to MSE**: When being $10,000 off is more than twice as bad as being $5,000 off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QugpK0zzlxCN"
      },
      "source": [
        "##4.3 Evalutating A Model with Cross Validation and Scoring parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpvcyTVpsIqC"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "np.random.seed(42)\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZQFNxarhCmn"
      },
      "source": [
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Cross-validation accuracy\n",
        "cv_acc = cross_val_score(clf, X , y , cv=5, scoring = None) #split X and y in 5 train-test sets, repeting it 5 times, 5 diferent scores --> make an average\n",
        "# if scoring =None, estimators default scoring evalutation metric is used (accuracy for classification models)\n",
        "cv_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCQvghZciP2d"
      },
      "source": [
        "# Cross-validated accuracy\n",
        "print(f'The cross-validated accuracy is : {np.mean(cv_acc)*100 :.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbHu_Kf0kyAn"
      },
      "source": [
        "np.random.seed(42)\n",
        "cv_acc = cross_val_score(clf, X , y , cv=5, scoring = \"accuracy\")\n",
        "cv_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-vcQYpLlM8e"
      },
      "source": [
        "print(f'The cross-validated accuracy is : {np.mean(cv_acc)*100 :.2f}%') #podem comprobar que ens dona el mateix, es a dir, per defecte si el scoring= None ens calcula la accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKRdxteDlYHZ"
      },
      "source": [
        "#Precision\n",
        "np.random.seed(42) #same splits each time\n",
        "cv_precision = cross_val_score(clf, X , y , cv= 5, scoring = \"precision\")\n",
        "cv_precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YPOTCgXlYXn"
      },
      "source": [
        "#we can see that there are 5 different values: depending on the split of the data our model perferoms better in one split (0.935) than another (0.763)\n",
        "#it depends on the split "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHtsvkLElYjn"
      },
      "source": [
        "# Cross-validated precision\n",
        "print(f'The cross-validated precision is : {np.mean(cv_precision)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ-ACTAOmmKy"
      },
      "source": [
        "#  Recall  - Indicates the proportion of actual positives which were correclty classified.\n",
        "cv_recall = cross_val_score(clf, X, y , cv= 5, scoring = \"recall\")\n",
        "cv_recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7iXu6fJy9TZ"
      },
      "source": [
        "# Cross-validated recall\n",
        "print(f'The cross-validated recall is : {np.mean(cv_recall)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRZUu4VrzQlR"
      },
      "source": [
        "Let's see the scoring parameter being in a regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQSRsVDIzYKb"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "np.random.seed(42)\n",
        "X = housing_df.drop(\"target\", axis = 1)\n",
        "y = housing_df[\"target\"]\n",
        "\n",
        "model = RandomForestRegressor(n_estimators = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-zbKTBszYEH"
      },
      "source": [
        "np.random.seed(42)\n",
        "cv_r2 = cross_val_score(model, X , y , cv=3, scoring = None) #split X and y in 3 train-test sets, repeting it 3 times, 3 diferent scores --> make an average\n",
        "np.mean(cv_r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkCBplWy0O2M"
      },
      "source": [
        "cv_r2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owMMCzVPzX_g"
      },
      "source": [
        "# Mean squared error\n",
        "cv_mse = cross_val_score(model, X, y, cv= 5, scoring= \"neg_mean_squared_error\")\n",
        "np.mean(cv_mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJF4AFcu23e7"
      },
      "source": [
        "cv_mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Lmyi2Y0OOz"
      },
      "source": [
        "# Mean absolut error\n",
        "cv_mae = cross_val_score(model, X, y , cv=5, scoring = \"neg_mean_absolute_error\")\n",
        "cv_mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7Hp3KTvl3z-"
      },
      "source": [
        "## 4.4 Using different Evaluation Metrics with Scikit-Learn functionss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbTuC8c7kxVQ"
      },
      "source": [
        "The 3rd way to evalute scikit-learn ML models/estimators is to using \"sklearn.metrics\" --> https://scikit-learn.org/stable/modules/classes#sklearn-metrics-metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su0mob4i7XsM"
      },
      "source": [
        "FOR CLASSIFICATION MODEL - only 1 single train_test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvd-sv8FsJTO"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create X & Y\n",
        "X = heart_disease.drop(\"target\", axis = 1)\n",
        "y = heart_disease[\"target\"]\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size= 0.2)\n",
        "\n",
        "# Create the model\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Fit the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Make predicitions\n",
        "y_preds = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model using evaluation funcitions\n",
        "print(\"Classifier metrics on the test set\")\n",
        "print(f\"Accuracy:{accuracy_score(y_test, y_preds)*100:.2f}%\")\n",
        "print(f\"Precision:{precision_score(y_test, y_preds)}\")\n",
        "print(f\"Recall:{recall_score(y_test, y_preds)}\")\n",
        "print(f\"F1:{f1_score(y_test, y_preds)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7pI1RVQ7cub"
      },
      "source": [
        "FOR REGRESSION MODEL - only 1 single train_test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CeNG7uY7GgC"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create X & Y\n",
        "X = housing_df.drop(\"target\", axis=1)\n",
        "y = housing_df\n",
        "\n",
        "# Split the data\n",
        "X = housing_df.drop(\"target\", axis=1)\n",
        "y = housing_df[\"target\"]\n",
        "\n",
        "# Create the model\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_preds = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model using evaluation funcitions\n",
        "print(\"Classifier metrics on the test set\")\n",
        "print(f\"r2 score:{r2_score(y_test, y_preds)}\")\n",
        "print(f\"MAE:{mean_absolute_error(y_test, y_preds)}\")\n",
        "print(f\"MSE:{mean_squared_error(y_test, y_preds)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUkmeY0TmOQh"
      },
      "source": [
        "# 5.Improving a ML Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEpiCNpSsJv8"
      },
      "source": [
        "First predicitions = baseline predictions\n",
        "First model = baseline model.\n",
        "\n",
        "From a data perspective:\n",
        "* Could we collect more data? (generally, the more data, the better)\n",
        "* Could we improve our data? (more depth information within each sample)\n",
        "\n",
        "From a model perspective:\n",
        "* Is there a model better we can use --> sklearn model map\n",
        "* Could we improve the current model? \n",
        "\n",
        "Hyperparameters vs. Parameters\n",
        " - Parameters = model find these paterns in data\n",
        " - Hyperparameters = settings on a model you can adjust to improve its ability to find patterns\n",
        "\n",
        "**3 ways to adjust hyperparameters**\n",
        " 1. By hand\n",
        " 2. Randomly with RandomSearchCV\n",
        " 3. Exhaustiverly with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_GrG1EcBKZU"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rih9RNAlBQeW"
      },
      "source": [
        "clf.get_params() #these are different hyperparameters that we can adjust in our RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY5DsNXDBhw8"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au58x64DByrY"
      },
      "source": [
        "#adjusting hyperparameters is like adjusting the temperature of the oven in order to improve the dish\n",
        "#default parameters --> find patterns well, but we can improve it by adjusting these ones."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz4OKqD2mXQr"
      },
      "source": [
        "### 5.1 Tunning Hyperparameters by hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX7BS2IIbf_P"
      },
      "source": [
        "3 SETS:\n",
        "\n",
        "* **Training split** (70-80%) - Course materials \n",
        "* **Validation split** (10-15%) - Practice exam\n",
        "* **Test split** (10-15%) - Final exam\n",
        "\n",
        "***Generalization:*** The ability for ML model to perfrom well on data it hasn't seen before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8bRj_3OsKWK"
      },
      "source": [
        "![title](https://media.springernature.com/full/springer-static/image/art%3A10.1007%2Fs13244-018-0639-9/MediaObjects/13244_2018_639_Fig8_HTML.png?as=webp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIGd6wRXcVWP"
      },
      "source": [
        "clf.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIsdn9qGcVMz"
      },
      "source": [
        "We're going to try and adjust:\n",
        "\n",
        "* 'max_depth'\n",
        "* 'max_features'\n",
        "* 'min_samples_leaf'\n",
        "* 'min_samples_split'\n",
        "* n_estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cVKCSEpcVA2"
      },
      "source": [
        "def evaluate_preds(y_true, y_preds):\n",
        "  \"\"\"\n",
        "  Performs evaluation comparision on y_true labels vs. y_preds labels on classification model\n",
        "  \"\"\"\n",
        "  accuracy = accuracy_score(y_true, y_preds)\n",
        "  precision = precision_score(y_true, y_preds)\n",
        "  recall = recall_score(y_true, y_preds)\n",
        "  f1 = f1_score(y_true, y_preds)\n",
        "  metric_dict = {\"accuracy\": round(accuracy,2),\n",
        "                 \"precision\": round(precision, 2),\n",
        "                 \"recall\": round(recall,2),\n",
        "                 \"f1\": round(f1,2)}\n",
        "  print(f\"Acc: {accuracy*100:2f}%\")\n",
        "  print(f\"Precision: {precision:2f}\")\n",
        "  print(f\"Recall: {recall:2f}\")\n",
        "  print(f\"F1 score: {f1:2f}\")\n",
        "\n",
        "  return metric_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLnxpJkDcU4G"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "np.random.seed(42)\n",
        "\n",
        "# Shuffle the data\n",
        "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
        "\n",
        "#Split into X & y\n",
        "X = heart_disease_shuffled.drop(\"target\", axis = 1)\n",
        "y = heart_disease_shuffled[\"target\"]\n",
        "\n",
        "# Split the data into train, validation & test sets\n",
        "train_split = round(0.7 * len(heart_disease_shuffled)) #70% of data\n",
        "valid_split = round(train_split + 0.15*len(heart_disease_shuffled)) #15% of data\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
        "X_test, y_test = X[valid_split:], y[valid_split:]\n",
        "\n",
        "len(X_train), len(X_valid), len(X_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Wn8ndwevMe"
      },
      "source": [
        "![title](https://miro.medium.com/max/875/1*f2KznlrIdj1MeobprVGBtg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uEILhUq1K9T"
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make baseline predicitions\n",
        "y_preds = clf.predict(X_valid)\n",
        "\n",
        "# Evaluate the classifier on validation seet\n",
        "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
        "baseline_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIODmN-SJM34"
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "#Create a second classifier with different hyperparameters\n",
        "clf_2 = RandomForestClassifier(n_estimators= 10)\n",
        "clf_2.fit(X_train,y_train)\n",
        "\n",
        "# Make predictions with different hyperparametrs\n",
        "y_preds_2 = clf_2.predict(X_valid)\n",
        "\n",
        "# Evaluate the 2nd classifier\n",
        "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSpRuZxK_0G"
      },
      "source": [
        "# By hand, let's adjunst all the hyperparameters --> Sckitlearn has a methods in built\n",
        "clf_3= RandomForestClassifier(n_estimators = 100, max_depth= 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6g8E5QHLP7l"
      },
      "source": [
        "### 5.2 Tunning Hyperparameters by Scikit-learn built-in function (RandomizedSearchCV)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA0HtAhpMKZH"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Create a dictionary with the hyperparameters we'd like to adjust as the \"keys\"\n",
        "# The values we want to try as the \"values\" of the dictionary\n",
        "\n",
        "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
        "        \"max_depth\": [None, 5, 10, 20, 30],\n",
        "        \"max_features\": [\"auto\", \"sqrt\"],\n",
        "        \"min_samples_split\": [2, 4, 6],\n",
        "        \"min_samples_leaf\": [1, 2, 4]}\n",
        "np.random.seed(42)\n",
        "\n",
        "# Split into X & y\n",
        "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
        "y = heart_disease_shuffled[\"target\"]\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "#Instantiate RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_jobs= -1) #n_jobs = how much of your comptures precssor you want to dedicate \n",
        "\n",
        "# Setup RandomizedSearchCV (CV = cross validation)\n",
        "rs_clf = RandomizedSearchCV(estimator=clf,\n",
        "                            param_distributions=grid,\n",
        "                            n_iter = 10, #number of models to try with different combinations of \"grid\" parameters\n",
        "                            cv=5,\n",
        "                            verbose=2)\n",
        "\n",
        "# Fit the RandomizedSearch CV version of clf\n",
        "rs_clf.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOIecP20MKLu"
      },
      "source": [
        " rs_clf.best_params_ #the best cv-results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZujQo72pMKDX"
      },
      "source": [
        "# Make predicitions with the best hyperparameters\n",
        "rs_y_preds= rs_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMwaOAQMMJ54"
      },
      "source": [
        "#We see that it has not improve by the \"manual setting\", but we can change the number of iterations, change it to 50 for example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9VFCnCTMJt3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}